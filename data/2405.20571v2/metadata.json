{
  "doi": "2405.20571v2",
  "content": [
    {
      "type": "text",
      "text": "We investigate the explicit expression for the principal eigenvalue $\\lambda_1^X(D)$ for a large class of compound Poisson processes $X$ on a bounded open set $D$ by examining its spectral heat content. When the jump density of the compound Poisson process is radially symmetric and strictly decreasing, we demonstrate that balls are the unique minimizers for $\\lambda_1^X(D)$ among all sets with equal Lebesgue measure. Furthermore, we show that this uniqueness fails if the jump density is not strictly decreasing.\n\nThe principal eigenvalue of stochastic processes on domains is of fundamental importance. One of the many practical implications of the principal eigenvalue is its role as a large deviation parameter, determining the decay rate of survival probability ([6, Equation 2.4]). An intriguing question in this context is what shape of domains minimizes the principal eigenvalue, ensuring the highest survival probability among all sets with equal Lebesgue measure. The answer lies in the celebrated Faber-Krahn inequality, which asserts that balls are the unique minimizers for the principal eigenvalue. However, except in very few cases, the explicit expression for the principal eigenvalue is not available, and one must rely on other objects such as torsion functions (expected lifetime) or the inradius of the underlying domains to estimate the principal eigenvalue (see [6]). Hence, calculating the precise value or finding the concrete expression for the principal eigenvalue becomes an important inquiry.\n\nThe primary objective of this paper is to study the principal eigenvalue of a broad class of compound Poisson processes and derive its explicit expression. Furthermore, when the jump density of the compound Poisson process is radially symmetric and strictly decreasing, we demonstrate that the principal eigenvalue is minimized on balls among all sets with equal Lebesgue measure (see Corollary 2.2). On the other hand, we provide a counterexample that this uniqueness of the minimal eigenvalue for balls breaks down in the absence of a strictly decreasing jump density.\n\nThe main device to prove the main results, Theorems 2.1 and 2.3, is the spectral heat content (SHC). For a Lévy process $Y = \\{Y_t\\}_{t \\ge 0}$ and a bounded open set $D$ in $\\mathbb{R}^d$, we define the spectral"
    },
    {
      "type": "text",
      "text": "heat content on \\(D\\) with respect to \\(Y\\) by\n\n\\[\nQ_D^Y(t) = \\int_D \\mathbb{P}_x(\\tau_D^Y > t) \\, dx,\n\\]\n\nwhere \\(\\tau_D^Y = \\inf\\{ t > 0 : Y_t \\notin D \\}\\) is the first exit time of \\(Y\\) from \\(D\\) and \\(\\mathbb{P}_x\\) is the law of \\(Y\\) started at \\(x\\). The spectral heat content for jump processes has been studied intensively in the last decade (see [7, 9, 10, 11] and references therein). When there exists a discrete spectrum for the infinitesimal generator of the process, the spectral heat content has the spectral representation (3.1), and one can obtain the principal eigenvalue from this representation. For compound Poisson processes, the spectral heat content also admits the jump decomposition (3.3), since there are only a countable number of jumps of which the duration of the next jump is strictly positive. This is a crucial property that holds only for compound Poisson processes. For general Lévy processes whose Lévy measures are infinite, the jump times are dense on \\([0, \\infty)\\) and the jump decomposition (3.3) of the spectral heat content does not hold. Extension to more general Lévy processes with infinite Lévy measure is certainly an interesting and natural question and this will be investigated in a future project.\n\nThe strategy to establish the main result is as follows. We first establish two technical lemmas, Lemmas 4.4 and 4.5. In Lemma 4.4, we prove that the jump chain, \\(S_n = J_1 + \\cdots + J_n\\), conditioned on \\(\\{ S_n \\in D \\}\\) converges to a uniform distribution on \\(D\\) as \\(n \\to \\infty\\). Intuitively speaking, if \\(D\\) is bounded, then it is difficult for the jump chain to stay inside a bounded open set \\(D\\) for large \\(n\\), meaning that there should be no preference for \\(S_n\\) to be in a certain region in \\(D\\) than another. Hence, the distribution of \\(S_n\\) conditioned on \\(\\{ S_n \\in D \\}\\) should converge to a uniform distribution on \\(D\\). Then, in Lemma 4.5, we compute the probability that the jump chain \\(S_{n+1}\\) started at \\(x \\in D\\) remains inside \\(D\\) conditioned on it has stayed inside \\(D\\) up to \\(n\\) and show that the conditional probability converges to the probability that a single jump \\(J_1\\) stays inside \\(D\\) averaged on all starting points \\(x \\in D\\). From these two facts, together with the comparison between the spectral decomposition (3.1) and the jump decomposition (3.3), we derive the precise expression for the principal eigenvalue in Theorem 2.1.\n\nAs an application of Theorem 2.1, we show that the principal eigenvalue for symmetric compound Poisson processes becomes minimized on balls among all sets with equal Lebesgue measure when the probability density function \\(j(x)\\) of an individual jump \\(J_1\\) of the underlying compound Poisson process is radially symmetric and strictly decreasing. The fact that balls are minimizers is proved in [1, Corollary 5.5] for a more general class of Lévy processes, but the ball being the unique minimizer for symmetric compound Poisson processes has not been studied in the past to the best of the authors’ knowledge. A natural question arises for the necessity of the condition that \\(j(x)\\) being radially symmetric or strictly decreasing. In Theorem 2.3, we show that the uniqueness fails by considering a compound Poisson process whose jump distribution is uniformly distributed over some set \\(A \\subset \\mathbb{R}^d\\), whose Lévy density is obviously not strictly decreasing. In fact, in Theorem 2.3, we characterize the maximal spectral heat content under volume constraint and observe that this"
    },
    {
      "type": "text",
      "text": "characterization has two scenarios depending on the relative size of the support of the jump and the underlying set D. When the Lebesgue measure |A| of the support of the jump is relatively small compared to the Lebesgue measure |D|, the spectral heat content becomes maximized when the domain D and the support of jump A are congruent ellipsoids. On the other hand, when |A| is relatively large compared to |D|, the spectral heat content becomes maximized as long as D − D ⊂ A. The intuition behind this fact is that when the support of jump is much larger than the size of D, the probability that the next jump stays inside D does not depend on the location from which it jumps, and each jump lands on D with the same probability |D|/|A|. The rigorous proof of the two cases depends on the characterization of the equality cases of Riesz’s inequality in [3]. When there exist discrete and countable eigenvalues, the non-uniqueness of minimal eigenvalues among all sets with equal Lebesgue measure follows from the non-uniqueness of maximal spectral heat contents and (3.2).\n\nThe paper is organized as follows. In Section 2, we state the main results of this paper. In Section 3, we recall necessary preliminaries such as Lévy processes, their semigroups, and rearrangement inequalities. We provide the proofs of the main results in Section 4.\n\nThe indicator function of a set A is denoted by 1_A. For a bounded set A, its Lebesgue measure is denoted by |A|. Let A, B ⊂ R^d be subsets of R^d, a ∈ R and z ∈ R^d. We define aA := {ax : x ∈ A}, z + A := {z + x : x ∈ A}, and A + B := {x + y : x ∈ A, y ∈ B}. We use P_x and E_x to denote the probability measure and expectation for processes starting at x ∈ R^d. When x = 0, we use P and E instead of P_0 and E_0. We reserve notation X = {X_t}_{t≥0} for compound Poisson processes and Y = {Y_t}_{t≥0} for generic Lévy processes.\n\nLet D be a bounded open set in R^d and λ_1^X(D) be the principal eigenvalue for the semigroup for a compound Poisson process X on D and j(x) be the probability density function for J_1 (see Section 3 for definitions).\n\n**Theorem 2.1**  Let X = {X_t}_{t≥0} be a compound Poisson process with jump rate r > 0. Assume that X satisfies Condition 4.1. For a bounded open set D, its principal eigenvalue λ_1^X(D) is given by\n\nλ_1^X(D) = (r / |D|) ∫_D ∫_{D^c} j(y − x) dy dx.\n\nIt follows from the Riesz's rearrangement inequality (see [8, Theorem 3.9])\n\n∫_D ∫_D j(y − x) dy dx ≤ ∫_{D^*} ∫_{D^*} j^*(y − x) dy dx,\n\nwhere j^* is the symmetric decreasing rearrangement of j (see Section 3 for the definition). Then, Theorem 2.1 implies\n\nλ_1^X(D) ≥ (r / |D|) ∫_{D^*} ∫_{(D^*)^c} j^*(y − x) dy dx = λ_1^{X^*}(D^*),  (2.1)"
    },
    {
      "type": "text",
      "text": "where \\( D^* \\) is a centered ball with \\( |D^*| = |D| \\) and \\( \\lambda_1^X(D) \\) and \\( \\lambda_1^{X^*}(D^*) \\) are the principal eigenvalues for the compound Poisson process \\( X \\) in \\( D \\) and the rotationally symmetrized process \\( X^* \\) in \\( D^* \\) (see Subsection 4.2 for the definition), respectively. Indeed, this was shown in [1] for more general Lévy processes. The following result characterizes equality cases when the probability density function \\( j(x) \\) is radially symmetric and strictly decreasing.\n\nCorollary 2.2 Let \\( D \\) be a bounded open set in \\( \\mathbb{R}^d \\) and \\( X^* \\) be the symmetrization of \\( X \\). If the probability density function \\( j(x) \\) of \\( J_1 \\) is radially symmetric and strictly decreasing, then the following Faber-Krahn inequality holds;\n\\[\n\\lambda_1^X(D) \\geq \\lambda_1^{X^*}(D^*).\n\\]\n\nFurthermore, the equality above holds if and only if \\( D \\) is a ball.\n\nProof. The inequality follows from (2.1). The proof for the equality cases follows from the equality case of strict rearrangement inequality [8, Theorem 3.9]. \n\nCorollary 2.2 asserts that the ball is the unique minimizer for the principal eigenvalue for the compound Poisson process when \\( j(x) \\) is radially symmetric and strictly decreasing. In Theorem 2.3, we show that if the jump density is not strictly decreasing, then the uniqueness of the minimizers for the principal eigenvalue fails. In fact, we investigate cases that guarantee the maximal spectral heat content for the compound Poisson process whose jump distribution is uniformly distributed on some subset \\( A \\subset \\mathbb{R}^d \\) without assuming Condition 4.1. When there exist discrete eigenvalues, the non-uniqueness of minimal principal eigenvalue follows from the non-uniqueness of maximal spectral heat content and (3.2).\n\nTheorem 2.3 Let \\( X = \\{X_t\\}_{t \\geq 0} \\) be a compound Poisson process, where the sequence of individual jumps \\( \\{J_i\\}_{i=1}^{\\infty} \\) is uniformly distributed on a bounded set \\( A \\subset \\mathbb{R}^d \\) and \\( X^* \\) be the symmetrization of \\( X \\). If \\( |A| < 2^d|D| \\), then the followings are equivalent:\n\nOn the other hand, if \\( |A| \\geq 2^d|D| \\), then the followings are equivalent:"
    },
    {
      "type": "text",
      "text": "Furthermore, assume that the spectral heat content for \\( X \\) has the spectral representation (3.1). If \\( |\\mathcal{A}| < 2^d|D| \\), then \\( \\lambda_1^X(D) \\) is minimized if \\( D = a + \\alpha\\mathcal{E} \\) and \\( A = \\gamma\\mathcal{E} \\) for some \\( a \\in \\mathbb{R}^d \\) and some ellipsoid \\( \\mathcal{E} \\subset \\mathbb{R}^d \\) up to measure zero. On the other hand, if \\( |\\mathcal{A}| \\geq 2^d|D| \\), then \\( \\lambda_1^X(D) \\) is minimized if \\( D - D \\subset A \\). Hence, the uniqueness of the minimal principal eigenvalue for balls does not hold.\n\nWe close this section by introducing further questions related to our main results.\n\nLet \\( (\\Omega, \\mathcal{F}, \\mathbb{P}) \\) be a probability space. A \\( d \\)-dimensional Lévy process \\( Y = \\{Y_t\\}_{t \\geq 0}\\) on \\( (\\Omega, \\mathcal{F}, \\mathbb{P}) \\) is a stochastic process with càdlàg paths and independent and stationary increments. The characteristic exponent \\( \\psi(\\xi) \\) of a Lévy process \\( Y = \\{Y_t\\}_{t \\geq 0} \\) is defined by \\( \\mathbb{E}[e^{i \\xi \\cdot Y_t}] = e^{-t \\psi(\\xi)} \\) for \\( \\xi \\in \\mathbb{R}^d \\). It follows from the Lévy–Khintchine theorem that \\( Y = \\{Y_t\\}_{t \\geq 0} \\) is a Lévy process with characteristic exponent \\( \\psi(\\xi) \\) if and only if there exists a triplet \\( (b, A, \\nu) \\) such that\n\n\\[\n\\psi(\\xi) = ib \\cdot \\xi + \\frac{1}{2} \\xi \\cdot A \\xi + \\int_{\\mathbb{R}^d} (1 - e^{i \\xi \\cdot y} + (i \\xi \\cdot y) 1_{\\{x:|x|<1\\}}(y)) \\nu(dy)\n\\]\n\nwhere \\( b \\in \\mathbb{R}^d \\), \\( A \\) is a positive semi-definite \\( d \\times d \\) matrix, and \\( \\nu \\) is a \\( \\sigma \\)-finite Borel measure on \\( \\mathbb{R}^d \\setminus \\{0\\} \\) satisfying \\( \\int_{\\mathbb{R}^d \\setminus \\{0\\}} (1 \\wedge |y|^2) \\nu(dy) < \\infty \\).\n\nLet \\( N = \\{N_t\\}_{t \\geq 0} \\) be a Poisson process with rate \\( r \\), that is \\( \\mathbb{P}(N_t = k) = e^{-rt} \\frac{(rt)^k}{k!},\\ k \\geq 0 \\).\nLet \\( S_n = J_1 + \\dots + J_n \\) be the jump chain, where \\( \\{J_i\\}_{i=1}^{\\infty} \\) is a sequence of i.i.d. random variables independent of \\( N \\) whose characteristic exponent is given by \\( \\phi(\\xi) := \\mathbb{E}[e^{i\\xi J_1}] = \\int_{\\mathbb{R}^d} e^{i \\xi \\cdot y} \\mu(dy) \\), where \\( \\mu \\) is a probability measure on \\( \\mathbb{R}^d \\) with \\( \\mu(\\{0\\}) = 0 \\). We define a compound Poisson process \\( X = \\{X_t\\}_{t \\geq 0} \\) with rate \\( r > 0 \\) and a jump measure \\( \\mu \\) by \\( X_t := S_{N_t} \\). When each \\( J_i \\) is symmetric, that is \\( \\mu(A) = \\mu(-A) \\) for all Borel sets \\( A \\), then \\( X \\) is also symmetric and we will call \\( X \\) a symmetric compound Poisson process. Note that\n\n\\[\n\\mathbb{E}[e^{i \\xi X_t}] = \\mathbb{E}[e^{i\\xi S_{N_t}}] = \\sum_{n=0}^{\\infty} \\mathbb{E}[e^{i\\xi S_n}, N_t = n] = \\sum_{n=0}^{\\infty} e^{-rt} \\frac{(rt)^n}{n!} \\phi(\\xi)^n = \\exp \\left(-rt \\int_{\\mathbb{R}^d} (1 - e^{i\\xi \\cdot y}) \\mu(dy)\\right).\n\\]"
    },
    {
      "type": "text",
      "text": "By the Lévy-Khintchine formula, this shows that the Lévy measure of \\( X \\) is \\( r\\mu \\).\n\nLet \\( D \\) be a bounded open set in \\( \\mathbb{R}^d \\) and \\( Y = \\{ Y_t \\}_{t \\geq 0} \\) a symmetric Lévy process. Let \\( P_t^D f(x) = \\mathbb{E}_x [ f(Y_t); t < \\tau_D ] \\) be a semigroup associated with the killed process \\( Y^D \\), where \\( Y_t^D = Y_t \\) if \\( t < \\tau_D^Y := \\inf \\{ t > 0 : Y_t \\notin D \\} \\) and \\( Y_t^D = \\partial \\) for \\( t \\geq \\tau_D^Y \\), where \\( \\partial \\) is a cemetery state. The infinitesimal generator \\( \\mathcal{L} \\) for the semigroup \\( (P_t^D)_{t \\geq 0} \\) is given by\n\n\\[\n\\mathcal{L} f(x) = \\lim_{t \\downarrow 0} \\frac{P_t^D f(x) - f(x)}{t},\n\\]\n\nwhenever the limit exists, where the limit is taken in the supremum norm. The generator of the strongly continuous semigroup is non-positive definite and self-adjoint. We assume that the generator \\( \\mathcal{L} \\) and the semigroup \\( P_t^D \\) admit discrete spectra \\( \\{ \\lambda_n^Y(D) \\}_{n=1}^\\infty \\) and \\( \\{ e^{- t \\lambda_n^Y(D)} \\}_{n=1}^\\infty \\) such that \\( P_t^D \\varphi_n^Y = e^{-t \\lambda_n^Y(D)} \\varphi_n^Y \\) and \\( \\mathcal{L} \\varphi_n^Y = \\lambda_n^Y(D) \\varphi_n^Y \\), where \\( \\{ \\varphi_n^Y \\} \\) is an orthonormal basis of eigenfunctions in \\( L^2(D) \\).\n\nAssume that \\( Y \\) admits a transition density \\( p_D^Y(t, x, y) \\) on \\( D \\). It is well-known that \\( p_D^Y(t, x, y) \\) has the following representation\n\n\\[\np_D^Y(t, x, y) = \\sum_{n=1}^\\infty e^{-t \\lambda_n^Y} \\varphi_n^Y(x) \\varphi_n^Y(y).\n\\]\n\nFrom this representation, the spectral heat content can be expressed as\n\n\\[\nQ_D^Y(t) = \\int_D \\mathbb{P}_x(\\tau_D^Y > t) \\, dx = \\int_D \\int_D p_D^Y(t, x, y) \\, dy \\, dx = \\sum_{n=1}^\\infty e^{-t \\lambda_n^Y} \\left( \\int_D \\varphi_n^Y(y) dy \\right)^2. \\tag{3.1}\n\\]\n\nWe call the above expression the spectral representation of the spectral heat content. This spectral representation will play an important role in proving Theorem 2.1. In particular, from (3.1) one can recover the principal eigenvalue \\( \\lambda_1^Y(D) \\) by the following expression\n\n\\[\n\\lambda_1^Y(D) = - \\lim_{t \\to \\infty} \\frac{\\ln Q_D^Y(t)}{t}. \\tag{3.2}\n\\]\n\nBesides the spectral decomposition, which holds for a large class of Lévy processes, the spectral heat content for a compound Poisson process has the following jump decomposition. Note that \\( X_t = S_{N_t} \\), where \\( S_n = J_1 + \\cdots + J_n \\), \\( N_t \\) is an independent Poisson process with rate \\( r \\) and \\( \\{ J_i \\}_{i=1}^\\infty \\) is a sequence of i.i.d. random variables. Since \\( \\{J_i\\}_{i=1}^\\infty \\) and \\( \\{N_t\\}_{t > 0} \\) are independent,\n\n\\[\n\\begin{align*}\nQ_D^X(t) &= \\int_D \\mathbb{P}_x(\\tau_D^X > t) dx \\\\\n&= \\sum_{n=0}^\\infty \\int_D \\mathbb{P}_x(\\tau_D^X > t,\\; N_t = n) dx \\\\\n&= \\sum_{n=0}^\\infty \\int_D \\mathbb{P}_x \\left( \\bigcap_{k=1}^n \\{ S_k \\in D \\},\\; N_t = n \\right) dx \\\\\n&= \\sum_{n=0}^\\infty e^{-rt} \\frac{(r t)^n}{n!} \\int_D A(x, n, D) dx,\n\\end{align*} \\tag{3.3}\n\\]\n\nwhere \\( A(x, n, D) = \\mathbb{P}_x\\left( \\bigcap_{k=1}^n \\{ S_k \\in D \\} \\right) \\)."
    },
    {
      "type": "text",
      "text": "For a subset \\( D \\subset \\mathbb{R}^d \\) with \\( |D| < \\infty \\), its symmetric rearrangement \\( D^* \\) is a centered ball with the same volume as \\( D \\). That is, \\( D^* = B(0, r) \\), where \\( \\omega_d r^d = |D| \\) and \\( \\omega_d = \\frac{\\pi^{d/2}}{\\Gamma(1+d/2)} \\) is the volume of a unit ball in \\( \\mathbb{R}^d \\). For a nonnegative function \\( f \\) with \\( |\\{x \\in \\mathbb{R}^d : f(x) > t\\}| < \\infty \\) for all \\( t > 0 \\), the symmetric decreasing rearrangement \\( f^* \\) is defined by\n\n\\[\nf^*(x) = \\int_0^\\infty 1_{\\{f(x)>t\\}}^* dt.\n\\]\n\nRiesz's rearrangement inequality [8, Theorems 3.7 and 3.9] states that\n\n\\[\n\\int_{\\mathbb{R}^d} \\int_{\\mathbb{R}^d} f(x)g(x-y)h(y) \\, dx \\, dy \\leq \\int_{\\mathbb{R}^d} \\int_{\\mathbb{R}^d} f^*(x)g^*(x-y)h^*(y) \\, dx \\, dy.\n\\]\n\nMore generally, if \\( f_1, f_2, \\ldots, f_m \\) are nonnegative functions with \\( |\\{x \\in \\mathbb{R}^d : f_i(x) > t\\}| < \\infty \\) for all \\( t > 0 \\) and for \\( i=1,2,\\ldots,m \\), and \\( B = (b_{ij}) \\) is a \\( k \\times m \\) matrix for \\( k \\leq m \\), then\n\n\\[\n\\int \\cdots \\int \\prod_{i=1}^m f_i \\left( \\sum_{j=1}^k b_{ij}x_j \\right) dx_1 \\cdots dx_k \\leq \\int \\cdots \\int \\prod_{i=1}^m f_i^* \\left( \\sum_{j=1}^k b_{ij}x_j \\right) dx_1 \\cdots dx_k. \\tag{3.4}\n\\]\n\nThis inequality is called the Brascamp–Lieb–Luttinger inequality [2, Theorem 1.2]. We use the following notations\n\n\\[\n\\mathcal{J}(f,g,h) := \\int (f * g)(x)h(x)dx, \\quad \\mathcal{J}(A,B,C) := \\mathcal{J}(1_A, 1_B, 1_C).\n\\]\n\nA natural question arises for the characterization of equality cases in Riesz’s rearrangement inequality. It follows from [8, Theorem 3.9] that if \\( g = g^* \\) and strictly decreasing, then \\( \\mathcal{J}(f,g,h) = \\mathcal{J}(f^*,g^*,h^*) \\) implies that \\( f \\) and \\( h \\) are radially symmetric up to the same translation, that is, there exists \\( y \\in \\mathbb{R}^d \\) such that \\( f(x) = f^*(x-y) \\) and \\( h(x) = h^*(x-y) \\). In [3], the author characterized the equality cases for Riesz’s rearrangement inequality when \\( f, g, h \\) are indicator functions.\n\n**Theorem 3.1 [3, Theorem 1]**\nLet \\( A, B \\) and \\( C \\) be measurable sets of finite positive measure in \\( \\mathbb{R}^d \\). Denote by \\( A^*, B^*, C^* \\) the centered balls of the same measure as \\( A, B, C \\), respectively, and let \\( \\alpha, \\beta, \\gamma \\) be the radii of these balls. If \\( |\\alpha - \\beta| < \\gamma < \\alpha + \\beta \\), then there is equality in\n\n\\[\n\\mathcal{J}(A,B,C) \\leq \\mathcal{J}(A^*, B^*, C^*) \\tag{3.5}\n\\]\n\nif and only if, up to sets of measure zero,\n\n\\[\nA = a + \\alpha \\mathcal{E}, \\quad B = b + \\beta \\mathcal{E}, \\quad C = c + \\gamma \\mathcal{E},\n\\]\n\nwhere \\( \\mathcal{E} \\) is a centered ellipsoid in \\( \\mathbb{R}^d \\), and \\( a, b \\) and \\( c = a+b \\) are vectors in \\( \\mathbb{R}^d \\). Otherwise, permute the three sets so that \\( \\gamma \\geq \\alpha + \\beta \\). Then, the equality in (3.5) holds if and only if \\( A + B \\subset C \\) up to a set of measure zero."
    },
    {
      "type": "text",
      "text": "In this section, we prove Theorem 2.1. Let \\( X = \\{X_t\\}_{t \\geq 0} \\) be a compound Poisson process with rate \\( r > 0 \\) and a jump measure \\( \\mu \\). Recall that \\( \\varphi(\\xi) = \\mathbb{E}[e^{i\\xi J_1}] = \\int_{\\mathbb{R}^d} e^{i\\xi y} \\mu(dy) \\), where \\( J_i \\) are jumps of the compound Poisson process. In this section, we assume the following conditions.\n\nCondition 4.1  1. \\( J_1 \\) has a symmetric probability density function \\( j(x) \\).\n\nHence, \\( p(t, x) := \\sum_{n=0}^\\infty e^{-rt} \\frac{(rt)^n}{n!} j^{\\otimes n}(x) \\) is the probability density function for \\( X_t \\).\n\n\\[\n\\mathbb{P}(X_t \\in A) = \\mathbb{P} \\bigg( \\sum_{i=1}^{N_t} J_i \\in A \\bigg) = \\sum_{n=0}^\\infty \\mathbb{P} \\bigg( \\sum_{i=1}^n J_i \\in A, N_t = n \\bigg)\n= \\sum_{n=0}^\\infty e^{-rt} \\frac{(rt)^n}{n!} \\int_A j^{\\otimes n}(x) dx.\n\\]\n\nRemark 4.2  1. Under the condition (2) in (4.1), \\( X_t \\) has a symmetric probability density function. Indeed, for any Borel set \\( A \\) \n\nWe recall the following version of the central limit theorem. The proof is given in [5, XV.5 Theorem 2] and the comment below it.\n\nLemma 4.3 ([5, XV.5 Theorem 2]) Let \\( \\{J_i\\}_{i=1}^\\infty \\) be a sequence of i.i.d. random variables with probability density function \\( j(x) \\). Suppose that \\( \\operatorname{Var}(J_1) < \\infty \\) and there exists a positive integer \\( k \\)"
    },
    {
      "type": "text",
      "text": "such that \\(|\\phi(\\xi)|^k\\) is integrable on \\(\\mathbb{R}^d\\), where \\(\\phi(\\xi) = \\mathbb{E}[e^{i\\xi J_1}]\\) is the characteristic function of \\(J_1\\). Let \\(j_n(x)\\) be the density of \\(\\frac{\\sum_{i=1}^n J_i}{\\sqrt{n \\mathrm{Var}(J_1)}}\\). Then, uniformly on \\(x \\in \\mathbb{R}^d\\),\n\n\\[\n\\lim_{n \\to \\infty} j_n(x) = (2\\pi)^{-d/2} e^{-\\frac{|x|^2}{2}}.\n\\]\n\nRecall that \\(S_n = \\sum_{i=1}^n J_i\\) is the jump chain of the underlying compound Poisson process. We show that conditional on \\(S_n \\in D\\), the distribution of \\(S_n\\) converges weakly to the uniform distribution on \\(D\\).\n\nFurthermore, the convergence is uniform for all \\(x \\in E\\).\n\n\\[\n\\lim_{n \\to \\infty} \\mathbb{E}_x \\left[ e^{i\\xi \\cdot S_n} \\mid S_n \\in D \\right] = \\frac{1}{|D|} \\int_{\\mathbb{R}^d} e^{i\\xi \\cdot w} 1_D(w) dw, \\quad \\xi \\in \\mathbb{R}^d\n\\]\n\n**Lemma 4.4** Let \\(D\\) be a bounded open set. Suppose the Condition 4.1 holds true. For any \\(x \\in \\mathbb{R}^d\\)\n\n**Proof.** Let \\(j_n(u)\\) be the transition density of \\(\\frac{S_n}{\\sigma \\sqrt{n}}\\) where \\(\\mathrm{Var}(J_1) = \\sigma^2\\). By the change of variable \\(\\sigma \\sqrt{n} u = v\\):\n\n\\[\n\\begin{aligned}\n\\mathbb{E}_x \\left[ e^{i\\xi \\cdot S_n} \\mid S_n \\in D \\right]\n&= \\frac{\\mathbb{E}_x \\left[ e^{i\\xi \\cdot S_n}; S_n \\in D \\right]}{\\mathbb{P}_x (S_n \\in D)}\n= \\frac{\\mathbb{E} \\left[ e^{i\\xi \\cdot (S_n + x)}; S_n \\in D \\right]}{\\mathbb{P}(S_n + x \\in D)} \\\\[2ex]\n&= \\frac{\\mathbb{E} \\left[ e^{i\\xi \\cdot x} e^{i\\xi \\cdot \\sigma \\sqrt{n} \\frac{S_n}{\\sigma\\sqrt{n}}}; \\frac{S_n}{\\sigma\\sqrt{n}} \\in \\frac{D-x}{\\sigma\\sqrt{n}} \\right]}{\\mathbb{P} \\left( \\frac{S_n}{\\sigma\\sqrt{n}} \\in \\frac{D-x}{\\sigma\\sqrt{n}} \\right) } \\\\[2ex]\n&= \\frac{\\int_{\\mathbb{R}^d} e^{i\\xi \\cdot x} e^{i \\sigma \\sqrt{n} \\xi \\cdot u} 1_{ \\frac{D-x}{\\sigma\\sqrt{n}}}(u) j_n(u) du}{\\int_{\\mathbb{R}^d} 1_{ \\frac{D-x}{\\sigma\\sqrt{n}}}(u) j_n(u) du} \\\\[2ex]\n&= \\frac{\\int_{\\mathbb{R}^d} e^{i\\xi \\cdot x} e^{i\\xi \\cdot v} 1_{D-x}(v) j_n\\left(\\frac{v}{\\sigma\\sqrt{n}}\\right) (\\sigma\\sqrt{n})^{-d} dv}{\\int_{\\mathbb{R}^d} 1_{D-x}(v) j_n\\left(\\frac{v}{\\sigma\\sqrt{n}}\\right) (\\sigma\\sqrt{n})^{-d} dv} \\\\[2ex]\n&= \\frac{ \\int_{\\mathbb{R}^d} e^{i\\xi \\cdot (x+v)} 1_D(x+v) j_n\\left(\\frac{v}{\\sigma\\sqrt{n}}\\right) dv }{ \\int_{\\mathbb{R}^d} 1_D(x+v) j_n\\left(\\frac{v}{\\sigma\\sqrt{n}}\\right) dv }.\n\\end{aligned}\n\\]\n\nLet \\(\\gamma(u) = (2\\pi)^{-d/2}e^{-\\frac{|u|^2}{2}}\\). By the change of variable \\(w = v + x\\), we obtain\n\n\\[\n\\begin{aligned}\n&\\left| \\int_{\\mathbb{R}^d} e^{i\\xi \\cdot (x+v)} 1_D(x + v) j_n\\left(\\frac{v}{\\sigma\\sqrt{n}}\\right) dv\n- \\int_{\\mathbb{R}^d} e^{i\\xi \\cdot w} 1_D(w) \\gamma(0) dw \\right| \\\\\n&\\leq \\int_{\\mathbb{R}^d} e^{i\\xi \\cdot (x+v)} 1_D(x+v) \\left| j_n\\left(\\frac{v}{\\sigma\\sqrt{n}}\\right) - \\gamma(0) \\right| dv \\\\\n&\\leq |D| \\sup_{v \\in D-x} \\left| j_n\\left(\\frac{v}{\\sigma\\sqrt{n}}\\right) - \\gamma(0) \\right| \\\\\n&\\leq |D| \\sup_{v \\in D-D} \\left| j_n\\left(\\frac{v}{\\sigma\\sqrt{n}}\\right) - \\gamma(0) \\right| ,\n\\end{aligned}\n\\]"
    },
    {
      "type": "text",
      "text": "where \\( D - D = \\{x - y : x, y \\in D\\} \\). It follows from Lemma 4.3 that the last expression converges to 0 as \\( n \\to \\infty \\). Using the same argument, uniformly for all \\( x \\in E \\), we have\n\n\\[\n\\lim_{n \\to \\infty} \\int_{\\mathbb{R}^d} 1_D(x + v) j_n \\left( \\frac{v}{\\sigma \\sqrt{n}} \\right) dv = |D| \\gamma(0).\n\\]\n\nHence, uniformly for all \\( x \\in E \\),\n\n\\[\n\\lim_{n \\to \\infty} \\frac{ \\int_{\\mathbb{R}^d} e^{i\\xi(x+v)} 1_D(x+v) j_n \\left( \\frac{v}{\\sigma \\sqrt{n}} \\right) dv } { \\int_{\\mathbb{R}^d} 1_D(x+v) j_n \\left( \\frac{v}{\\sigma \\sqrt{n}} \\right) dv }\n= \\frac{1}{|D|} \\int_{\\mathbb{R}^d} e^{i\\xi \\cdot w} 1_D(w) dv.\n\\]\n\\(\\Box\\)\n\n**Lemma 4.5** Let \\( D \\) be a bounded open set. Suppose that the Condition 4.1 holds true. For any \\( x \\in \\mathbb{R}^d \\) we have\n\\[\n\\lim_{n \\to \\infty} \\mathbb{P}_x \\left( S_{n+1} \\in D \\Bigg| \\bigcap_{k=1}^n \\{ S_k \\in D \\} \\right)\n= \\frac{1}{|D|} \\int_D \\mathbb{P}_x(J_1 \\in D) dx = \\frac{1}{|D|} \\int_D \\int_D j(x+u) du\\, dx.\n\\]\nFurthermore, the convergence is uniform for all \\( x \\in E \\).\n\n**Proof.**\nBy the strong Markov property, we have\n\\[\n\\mathbb{P}_x \\left( S_{n+1} \\in D \\Bigg| \\bigcap_{k=1}^n \\{ S_k \\in D \\} \\right)\n= \\frac{ \\mathbb{P}_x (S_{n+1} \\in D, \\bigcap_{k=1}^n \\{ S_k \\in D \\}) }{ \\mathbb{P}_x (\\bigcap_{k=1}^n \\{ S_k \\in D \\}) }\n\\]\n\\[\n= \\frac{ \\mathbb{E}_x [ \\mathbb{P}_{S_n}(J_{n+1} \\in D);\\, \\bigcap_{k=1}^n \\{ S_k \\in D\\} ] }{ \\mathbb{P}_x (\\bigcap_{k=1}^n \\{ S_k \\in D \\}) }.\n\\]\n\nFrom Lemma 4.4 the distribution of \\( S_n \\), conditioned on \\( S_n \\in D \\), converges weakly to the uniform distribution on \\( E \\). Hence, the independence and the weak convergence yield that\n\\[\n\\lim_{n \\to \\infty} \\mathbb{P}_{S_n}(J_{n+1} \\in D) = \\frac{1}{|D|} \\int_D \\mathbb{P}_z(J_1 \\in D) dz,\n\\]\nas it is conditioned on the event \\( S_n \\in D \\) in the numerator. Now, the conclusion follows from the bounded convergence theorem and cancellation between the same expressions \\( \\mathbb{P}_x (\\bigcap_{k=1}^n \\{ S_k \\in D \\}) \\) in the numerator and denominator.\n\\(\\Box\\)\n\nWe are now ready to prove Theorem 2.1.\n\n**Proof of Theorem 2.1.**\nRecall from (3.3) that the spectral heat content \\( Q_D^X(t) \\) has the following jump decomposition\n\n\\[\nQ_D^X(t) = \\int_D \\mathbb{P}_x(\\tau_D^X > t) dx = \\sum_{n=0}^{\\infty} e^{-rt} \\frac{(rt)^n}{n!} \\int_D A(x, n, D) dx,\n\\]\n\n10"
    },
    {
      "type": "text",
      "text": "where \\( A(x, n, D) = \\mathbb{P}_x\\left( \\bigcap_{k=1}^n \\{ S_k \\in D \\} \\right) \\). Let \\( \\alpha = \\frac{1}{|D|} \\int_D \\mathbb{P}_z(J_1 \\in D) dz \\) for simplicity. From (3.2), it suffices to show that\n\n\\[\n\\lim_{t \\to \\infty} \\frac{\\log Q_D^X(t)}{t} = -r(1-\\alpha).\n\\]\n\nGiven \\( \\varepsilon > 0 \\) with \\( \\varepsilon < \\alpha \\), it follows from Lemma 4.5 that there exists \\( N = N(\\varepsilon) \\) such that\n\n\\[\n\\alpha - \\varepsilon < \\mathbb{P}_x \\left( S_n \\in D \\mid \\bigcap_{k=1}^{n-1} \\{ S_k \\in D \\} \\right) < \\alpha + \\varepsilon \\tag{4.1}\n\\]\n\nfor all \\( n \\geq N \\) and \\( x \\in D \\). Hence, for all \\( n \\geq N \\) and \\( x \\in D \\)\n\n\\[\n\\begin{aligned}\nA(x, n, D) &= \\mathbb{P}_x \\left( \\bigcap_{k=1}^{N-1} \\{ S_k \\in D \\} \\right) \\prod_{k=N}^n \\mathbb{P}_x \\left( S_k \\in D \\mid \\bigcap_{j=1}^{k-1} \\{ S_j \\in D \\} \\right) \\\\\n&\\leq \\prod_{k=N}^n \\mathbb{P}_x \\left( S_k \\in D \\mid \\bigcap_{j=1}^{k-1} \\{ S_j \\in D \\} \\right) \\\\\n&\\leq (\\alpha + \\varepsilon)^{n-N+1}.\n\\end{aligned}\n\\]\n\nUsing a trivial upper bound \\( A(x, n, D) \\leq 1 \\),\n\n\\[\n\\begin{aligned}\nQ_D^X(t) &= \\sum_{n=0}^\\infty e^{-rt} \\frac{(rt)^n}{n!} \\int_D A(x, n, D) dx \\\\\n&\\leq |D| \\left( \\sum_{n=0}^{N-1} e^{-rt} \\frac{(rt)^n}{n!} + \\sum_{n=N}^\\infty e^{-rt} \\frac{(rt)^n}{n!} (\\alpha + \\varepsilon)^{n-N+1} \\right) \\\\\n&\\leq |D| \\left( \\sum_{n=0}^{N-1} e^{-rt} \\frac{(rt)^n}{n!} + (\\alpha + \\varepsilon)^{-N+1} e^{rt(\\alpha + \\varepsilon - 1)} \\right).\n\\end{aligned}\n\\]\n\nTaking logarithm and letting \\( t \\to \\infty \\)\n\n\\[\n\\limsup_{t \\to \\infty} \\frac{\\log Q_D^X(t)}{t} \\leq -r(1 - \\alpha) + r \\varepsilon.\n\\]\n\nSince \\( \\varepsilon > 0 \\) is arbitrary we conclude that\n\n\\[\n\\limsup_{t \\to \\infty} \\frac{\\log Q_D^X(t)}{t} \\leq -r(1 - \\alpha).\n\\]\n\nFor the lower bound, it follows from (4.1) that for all \\( n \\geq N \\) and \\( x \\in D \\),\n\n\\[\nA(x, n, D) = \\mathbb{P}_x \\left( \\bigcap_{k=1}^{N-1} \\{ S_k \\in D \\} \\right) \\prod_{k=N}^n \\mathbb{P}_x \\left( S_k \\in D \\mid \\bigcap_{j=1}^{k-1} \\{ S_j \\in D \\} \\right)\n\\]"
    },
    {
      "type": "text",
      "text": "1. \nIn this section, we prove Theorem 2.3 when the distribution of \\( J_1 \\) of the underlying compound Poisson process is uniformly distributed on a set \\( A \\subset \\mathbb{R}^d \\). Note that we do not impose the Condition 4.1 for the current section, which were used to derive Lemmas 4.4 and 4.5. For a compound Poisson process \\( X_t = S_{N_t} \\), we define the symmetrized compound Poisson process \\( X_t^* = S_{N_t}^* \\) where \\( \\{J_i^*\\}_{i=1}^\\infty \\) is a sequence of i.i.d. random variables with probability density function \\( j^* \\) and \\( S_n^* = \\sum_{i=1}^n J_i^* \\). We call \\( X^* \\) the symmetrization of \\( X \\). Then, we define\n\n2.\n\\[\nA(x, n, D) = \\mathbb{P}_x \\left(\\bigcap_{k=1}^n \\{S_k \\in D\\}\\right), \\qquad\nA^*(x, n, D) = \\mathbb{P}_x \\left(\\bigcap_{k=1}^n \\{S_k^* \\in D\\}\\right).\n\\]\n\n3.\n\\[\n\\liminf_{t \\to \\infty} \\frac{\\log Q_D^X(t)}{t} \\geq -r(1-\\alpha) - r\\varepsilon.\n\\]\n\n4.\nFurthermore, since \\( \\alpha > \\varepsilon \\) and \\( N \\) is fixed, we may decrease the value of \\( c \\), if necessary, so that\n\n5.\n\\[\nQ_D^X(t) \\geq ce^{-rt} \\left( e^{rt(\\alpha-\\varepsilon)} - \\sum_{n=0}^{N-1} \\frac{(rt)^n}{n!}(\\alpha-\\varepsilon)^n \\right).\n\\]\n\n6.\n\\[\n\\liminf_{t \\to \\infty} \\frac{\\log Q_D^X(t)}{t} \\geq -r(1 - \\alpha)\n\\]\n\n7.\n\\[\n\\geq \\mathbb{P}_x\\left(\\bigcap_{k=1}^{N-1} \\{S_k \\in D\\}\\right) (\\alpha - \\varepsilon)^{n-N+1}\n\\]\n\n8.\nfor all sufficiently large \\( t > 0 \\). Taking logarithm and letting \\( t \\to \\infty \\) yield\n\n9.\nSince \\( \\varepsilon > 0 \\) is arbitrary we conclude that\n\n10.\nHence,\n\n11.\n\\[\nQ_D^X(t) \\geq c e^{-rt(1-\\alpha+\\varepsilon)}.\n\\]\n\n12.\nHence, for any constant \\( c < (\\alpha - \\varepsilon)^{-N+1} \\int_D \\mathbb{P}_x \\left(\\bigcap_{k=1}^{N-1} \\{S_k \\in D\\}\\right) dx \\), we have\n\n13.\n\\[\nQ_D^X(t) \\geq \\sum_{n=N}^{\\infty} e^{-rt} \\frac{(rt)^n}{n!} \\int_D \\mathbb{P}_x \\left(\\bigcap_{k=1}^{N-1} \\{S_k \\in D\\}\\right) (\\alpha - \\varepsilon)^{n-N+1} dx\n\\]\n\\[\n\\geq e^{-rt} (\\alpha-\\varepsilon)^{-N+1} \\left( e^{rt(\\alpha-\\varepsilon)} - \\sum_{n=0}^{N-1} \\frac{(rt)^n}{n!} (\\alpha-\\varepsilon)^n \\right) \\int_D \\mathbb{P}_x \\left(\\bigcap_{k=1}^{N-1} \\{S_k \\in D\\}\\right) dx.\n\\]"
    },
    {
      "type": "text",
      "text": "Note that\n\n\\[\n\\int_D A(x,n,D)\\,dx = \\int_{\\mathbb{R}} 1_D(x) \\int_{(\\mathbb{R})^n} 1_D(x+x_1)\\cdots 1_D(x+x_1+\\cdots+x_n) \\prod_{i=1}^n j(x_i) \\,dx_1\\cdots dx_n dx\n\\]\n\n\\[\n= \\int_{\\mathbb{R}^{n+1}} \\prod_{l=0}^{n} 1_D\\left(x + \\sum_{k=1}^l x_k\\right) \\prod_{i=1}^n j(x_i)\\, dx_1\\cdots dx_n dx.\n\\]\n\nIt follows from Brascamp–Lieb–Luttinger inequality (3.4) that\n\n\\[\n\\int_D A(x,n,D)\\,dx \\leq \\int_{\\mathbb{R}^{n+1}} \\prod_{l=0}^{n} 1_{D^*}\\left(x + \\sum_{k=1}^l x_k\\right) \\prod_{i=1}^n j^*(x_i)\\,dx_1\\cdots dx_n dx\n\\]\n\n\\[\n= \\int_{D^*} A^*(x,n,D^*)\\,dx.\n\\]\n\nWe observe that the spectral heat content is invariant under linear isomorphisms. Let \\(T : \\mathbb{R}^d \\to \\mathbb{R}^d\\) be a linear isomorphism with \\(|\\det(T)| = 1\\) and \\(D,A\\subset\\mathbb{R}^d\\) be open sets. Let \\(\\{J_i\\}_{i=1}^\\infty, \\{\\tilde{J}_i\\}_{i=1}^\\infty\\) be sequences of random variables with densities \\(j\\) and \\(\\tilde{j} = T \\circ j\\) respectively. Let \\(N_t\\) be a Poisson process with rate \\(r>0\\), \\(S_n = \\sum_{i=1}^n J_i\\), and \\(\\tilde{S}_n = \\sum_{i=1}^n \\tilde{J}_i\\). Define \\(X_t = S_{N_t}\\) and \\(\\tilde{X}_t = \\tilde{S}_{N_t}\\). Then, we have \\(Q_D^X(t) = Q_{T(D)}^{\\tilde{X}}(t)\\) for all \\(t>0\\). Indeed, the result follows from\n\n\\[\nQ_D^X(t) = \\sum_{n=0}^\\infty e^{-rt} \\frac{(rt)^n}{n!} \\int_D A(x,n,D)\\,dx\n\\]\n\nwhere \\(A(x,n,D) = \\mathbb{P}_x\\left(\\bigcap_{k=1}^n\\{S_k \\in D\\}\\right)\\) and\n\n\\[\n\\int_D A(x,n,D)\\,dx = \\int_{T(D)} \\tilde{A}(x,n,T(D))\\,dx,\n\\]\nby the change of variables.\n\n## Proposition 4.6\nLet \\(X_t = \\sum_{i=1}^{N_t} J_i\\) be a compound Poisson process, where \\(J_i\\) is uniformly distributed on a set \\(A\\subset \\mathbb{R}^d\\) and \\(X^*\\) be the symmetrization of \\(X\\). Assume that \\(|A| < 2^d |E|\\). Then, the followings are equivalent:\n\n1. \\(Q_D^X(t) = Q_{D^*}^{X^*}(t)\\) for all \\(t>0\\).\n\n2. \\(Q_D^X(t) = Q_{D^*}^{X^*}(t)\\) for some \\(t>0\\).\n\n3. \\(D = a + bE\\) and \\(A = cE\\), where \\(a \\in \\mathbb{R}^d\\), \\(b,c\\in \\mathbb{R}\\), and \\(E\\) is a centered ellipsoid in \\(\\mathbb{R}^d\\).\n\n### Proof.\nClearly, the first condition implies the second.\n\nSecondly, assume that \\(Q_E^X(t) = Q_{E^*}^{X^*}(t)\\) for some \\(t > 0\\). From [1, Corollary 5.5] \\(Q_E^X(t) \\leq Q_{E^*}^{X^*}(t)\\) and from the jump decomposition (3.3) of the spectral heat content, we must have\n\n\\[\n\\int_D A(x,n,D)\\,dx = \\int_{D^*} A^*(x,n,D^*)\\,dx\n\\]"
    },
    {
      "type": "text",
      "text": "for all $n \\in \\mathbb{N}$. By the change of variable $y = -x$\n\n$$\n\\int_D A(x, 1, D) dx = \\int_D \\mathbb{P}_x(J_1 \\in D) dx = \\int_{-D} \\mathbb{P}_{-y}(J_1 \\in D) dy\n$$\n\n$$\n= \\int_{\\mathbb{R}^d} 1_{-D}(y) \\int_{\\mathbb{R}^d} 1_D(-y + z) \\frac{1_A(z)}{|A|} dz dy\n$$\n\n$$\n= \\int_{\\mathbb{R}^d} \\frac{1_A(z)}{|A|} \\int_{\\mathbb{R}^d} 1_{-D}(y) 1_D(-y + z) dy dz\n$$\n\n$$\n= \\int_{\\mathbb{R}^d} \\frac{1_A(z)}{|A|} (1_{-D} * 1_D)(z) dz\n$$\n\n$$\n= \\mathcal{J}(1_{-D}, 1_D, 1_A).\n$$\n\nSimilarly, $\\int_{D^*} A^*(x, 1, D^*) dx = \\mathcal{J}(1_{(-D)^*}, 1_{D^*}, 1_{A^*})$, which in turn implies $\\mathcal{J}(1_{-D}, 1_D, 1_A) = \\mathcal{J}(1_{(-D)^*}, 1_{D^*}, 1_{A^*})$. Recall that in Theorem 3.1 $\\alpha, \\beta,$ and $\\gamma$ represent the radii of underlying three sets arranged in an increasing order. In our setting, $\\alpha$ and $\\beta$ are the radius of $D^*$ and $\\gamma$ is the radius of $A^*$. Hence, the condition $|\\alpha - \\beta| < \\gamma < \\alpha + \\beta$ in Theorem 3.1 is equivalent to $|A| < |2D| = 2^d |D|$. It follows from Theorem 3.1 $D = a + b\\mathcal{E}$ and $A = c\\mathcal{E}$ for some centered ellipsoid $\\mathcal{E}$.\n\nFinally, suppose that $D = a + b\\mathcal{E}$ and $A = c\\mathcal{E}$, where $a \\in \\mathbb{R}^d$ and $\\mathcal{E}$ is a centered ellipsoid in $\\mathbb{R}^d$. Since the spectral heat content is translation invariant, we may assume that $a = 0$. Then, there exists a linear isomorphism $T$ such that $T(D) = D^*$ and $T(A) = A^*$. By the change of variables, for any $t > 0$ we have\n\n$$\nQ_D^X(t) = \\sum_{n=0}^{\\infty} e^{-rt} \\frac{(rt)^n}{n!} \\int_D A(x, n, D) dx\n$$\n\n$$\n= \\sum_{n=0}^{\\infty} e^{-rt} \\frac{(rt)^n}{n!} \\int_{T(D)} \\tilde{A}(x, n, T(D)) dx = Q_{D^*}^{X^*}(t).\n$$\n\n$\\Box$\n\nNow we study the case $|A| \\geq 2^d|D|$.\n\n## Proposition 4.7\nLet $X_t = S_{N_t}$ be a compound Poisson process whose jump distribution is uniform on a set $A \\subset \\mathbb{R}^d$ and $X^*$ be the symmetrization of $X$. Assume that $|A| \\geq 2^d |D|$. Then, the followings are equivalent:\n\n1. $Q_D^X(t) = Q_{D^*}^{X^*}(t)$ for all $t > 0$.\n\n2. $Q_D^X(t) = Q_{D^*}^{X^*}(t)$ for some $t > 0$.\n\n3. $D - D \\subset A$ up to measure zero, where $D - D := \\{x - y : x, y \\in D\\}$.\n\n4. $Q_D^X(t) = |D| \\exp\\left(-rt\\left(1 - \\frac{|D|}{|A|}\\right)\\right)$ for all $t > 0$."
    },
    {
      "type": "text",
      "text": "Proof. Clearly, the first condition implies the second.\n\nSecondly, suppose that \\( Q_D^X(t) = Q_{D^*}^{X^*}(t) \\) for some \\( t > 0 \\). It follows from the proof of Proposition 4.6 we have \\( \\mathcal{J}(1_{-D}, 1_D, 1_A) = \\mathcal{J}(1_{D^*}, 1_{D^*}, 1_{A^*}) \\). The condition \\( |A| \\geq 2^d |D| \\) is equivalent to \\( \\gamma \\geq \\alpha + \\beta \\) in Theorem 3.1 and from Theorem 3.1, we conclude \\( D - D \\subset A \\).\n\nThirdly, assume that \\( D - D \\subset A \\). Without loss of generality, we may assume \\( x = 0 \\) and \\( 0 \\in D \\). Since \\( D = D - 0 \\subset D + (-D) \\subset A \\)\n\n\\[\nA(0,1,D) = \\int_{\\mathbb{R}^d} 1_D(y) \\frac{1}{|A|} 1_A(y) dy = \\frac{1}{|A|} \\int_{\\mathbb{R}^d} 1_{D \\cap A}(y) dy = \\frac{1}{|A|} \\int_{\\mathbb{R}^d} 1_D(y) dy = \\frac{|D|}{|A|}.\n\\]\n\nSimilarly, by the chain rule for conditional probability, we have\n\n\\[\nA(0,n,D) = \\mathbb{P}\\left( \\bigcap_{k=1}^n \\{ S_k \\in D \\} \\right) = \\prod_{k=1}^n \\mathbb{P} \\left( S_k \\in D \\bigg| \\bigcap_{j=1}^{k-1} \\{ S_j \\in D \\} \\right).\n\\]\n\nWe will show that \\( \\mathbb{P} \\left( S_k \\in D \\bigg| \\bigcap_{j=1}^{k-1} \\{ S_j \\in D \\} \\right) = \\frac{|D|}{|A|} \\) for each \\( 1 \\leq k \\leq n \\). Let \\( j_{k-1}(y_1, \\cdots, y_{k-1}) \\) be the joint density for \\( (S_1, \\cdots, S_{k-1}) \\). Since \\( \\{S_j\\}_{j=1}^{k-1} \\) and \\( J_k \\) are independent, their joint density is \\( j_{k-1}(y_1, \\cdots, y_{k-1}) \\cdot \\frac{1}{|A|} 1_A(z) \\). Hence,\n\n\\[\n\\begin{aligned}\n\\mathbb{P}\\left( S_k \\in D \\bigg| \\bigcap_{j=1}^{k-1} \\{ S_j \\in D \\} \\right)\n&= \\frac{\\mathbb{P}\\left( \\bigcap_{j=1}^{k-1} \\{ S_j \\in D \\}, S_{k-1} + J_k \\in D \\right)}{\\mathbb{P} \\left( \\bigcap_{j=1}^{k-1} \\{ S_j \\in D \\} \\right)} \\\\\n&= \\frac{1}{\\mathbb{P} \\left( \\bigcap_{j=1}^{k-1} \\{ S_j \\in D \\} \\right)} \\int_{(\\mathbb{R}^d)^{k-1}} \\int_{\\mathbb{R}^d} 1_{D^{k-1}}(y_1,\\cdots,y_{k-1}) 1_{D-y_{k-1}}(z) j_{k-1}(y_1,\\cdots,y_{k-1}) \\frac{1_A(z)}{|A|} dz dy_1 \\cdots dy_{k-1} \\\\\n&= \\frac{1}{\\mathbb{P} \\left( \\bigcap_{j=1}^{k-1} \\{ S_j \\in D \\} \\right)} \\int_{(\\mathbb{R}^d)^{k-1}} 1_{D^{k-1}}(y_1,\\cdots,y_{k-1}) j_{k-1}(y_1,\\cdots,y_{k-1}) \\int_{\\mathbb{R}^d} 1_{D-y_{k-1}}(z) \\frac{1_A(z)}{|A|} dz dy_1\\cdots dy_{k-1} \\\\\n&= \\frac{1}{\\mathbb{P} \\left( \\bigcap_{j=1}^{k-1} \\{ S_j \\in D \\} \\right)} \\int_{(\\mathbb{R}^d)^{k-1}} 1_{D^{k-1}}(y_1,\\cdots,y_{k-1}) j_{k-1}(y_1,\\cdots,y_{k-1}) \\frac{|(D-y_{k-1})\\cap A|}{|A|} dy_1\\cdots dy_{k-1} \\\\\n&= \\frac{|D-y_{k-1}|}{|A|} = \\frac{|D|}{|A|},\n\\end{aligned}\n\\]\n\nwhere we used the fact \\( D-y_{k-1} \\subset D-D \\subset A \\). This establishes \\( \\mathbb{P} \\left( S_k \\in D \\bigg| \\bigcap_{j=1}^{k-1} \\{ S_j \\in D \\} \\right) = \\frac{|D|}{|A|} \\) for each \\( 1 \\leq k \\leq n \\) and \\( A(0,n,D) = \\left( \\frac{|D|}{|A|} \\right)^n \\) for all \\( n \\geq 1 \\). Then,\n\n\\[\nQ_D^X(t) = \\sum_{n=0}^{\\infty} e^{-rt} \\frac{(rt)^n}{n!} \\int_D A(x,n,E) dx = \\sum_{n=0}^\\infty |D|\\left( \\frac{|D|}{|A|} \\right)^n \\cdot e^{-rt} \\frac{(rt)^n}{n!} = |D| \\exp\\left( -rt \\left( 1 - \\frac{|D|}{|A|} \\right) \\right).\n\\]\n\nFinally, assume the spectral heat content is given by \\( Q_D^X(t) = |D| \\exp\\left( -rt \\left( 1 - \\frac{|D|}{|A|} \\right) \\right) \\). By repeating the same argument for \\( X^* \\) and \\( D^* \\), we know that \\( Q_{D^*}^{X^*}(t) = |D| \\exp\\left( -rt \\left( 1 - \\frac{|D|}{|A|} \\right) \\right) \\) and this implies \\( Q_D^X(t) = Q_{D^*}^{X^*}(t) \\) for all \\( t > 0 \\).\n\\(\\Box\\)"
    },
    {
      "type": "text",
      "text": "We are now ready to prove Theorem 2.3.\n\nProof of Theorem 2.3. The first part on the equivalent conditions follows from Propositions 4.6 and 4.7.\n\nAssume that the spectral heat content for the process \\( X \\) has the spectral representation (3.1). From [1, Corollary 5.5], \\( Q_D^X(t) \\leq Q_{D^*}^{X^*}(t) \\) for all \\( t > 0 \\), and the principal eigenvalue \\( \\lambda_1^X \\) can be obtained using (3.2). Hence, any equivalent condition on the maximality of the spectral heat content guarantees the minimality of the principal eigenvalue. \\(\\Box\\)\n\nAcknowledgment: The second-named author is grateful to Professor Younghwan Son (POSTECH, South Korea) for the discussion and helpful comments on Lemmas 4.4 and 4.5."
    },
    {
      "type": "text",
      "text": "Daesung Kim\nSchool of Mathematics, Georgia Institute of Technology, GA 30332, USA\nE-mail: dkim3009@gatech.edu\n\nHyunchul Park\nDepartment of Mathematics, State University of New York at New Paltz, NY 12561, USA\nSchool of Mathematics, Korea Institute for Advanced Study, Seoul, South Korea\nE-mail: parkh@newpaltz.edu"
    }
  ],
  "images": [],
  "pdf": "2405.20571v2_err1.pdf"
}