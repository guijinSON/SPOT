{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8209b950-01ee-4115-aad6-347b407b2129",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "model_name = \"openrouter/google/gemini-2.5-pro-preview-03-25\"\n",
    "model_name = model_name.replace('/','_').replace('.','_')\n",
    "\n",
    "scores = []\n",
    "for fp in os.listdir('results'):\n",
    "    if fp.startswith(model_name):\n",
    "        if 'metrics' in fp:\n",
    "            scores.append(pd.read_csv(f'results/{fp}'))\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "eb415415-4a2a-4399-bafa-382ea1a97dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv(\n",
    "    \"results_scaling/o4_med_2_resp_df.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "151cbb44-a88d-4b84-90cd-94dad025024b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o4_high_resp_df.csv\n",
      "o4_high_1_resp_df.csv\n",
      "o4_high_resp_df_3.csv\n",
      "pass@1: 0.150 (99% CI: 0.121–0.212), std: 0.042\n",
      "pass@2: 0.280 (99% CI: 0.212–0.333), std: 0.052\n"
     ]
    }
   ],
   "source": [
    "import os, ast, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src import compute_all_metrics\n",
    "\n",
    "# model_name = \"openrouter_qwen_qwen2_5-vl-32b-instruct\"\n",
    "model_name = \"o4_high\"\n",
    "\n",
    "# model_name = \"gpt-4.1\"\n",
    "# model_name = \"openrouter_qwen_qwen3-235b\"\n",
    "# model_name = \"openrouter_google_gemini-2_0-flash-lite-001\"\n",
    "# model_name = \"openrouter_google_gemini-2_5\"\n",
    "# model_name = \"openrouter_qwen_qwen-2_5-vl-72b-instruct\"\n",
    "\n",
    "results_path = \"results_scaling\"\n",
    "safe_name  = model_name.replace('/', '_').replace('.', '_')\n",
    "group_cols = ['doi/arxiv_id','error_category','error_severity','paper_category']\n",
    "\n",
    "def parse_list(cell):\n",
    "    if pd.isna(cell): return []\n",
    "    if isinstance(cell, str):\n",
    "        try:    return ast.literal_eval(cell)\n",
    "        except: return []\n",
    "    return list(cell) if hasattr(cell, '__iter__') else []\n",
    "\n",
    "# 1) Build a long DataFrame of (error, file, detected)\n",
    "rows = []\n",
    "dfs = []\n",
    "for fn in os.listdir(results_path ):\n",
    "    if (fn.startswith(safe_name)) & ('metrics' in fn):\n",
    "        # df = pd.read_csv(os.path.join(results_path , fn))\n",
    "        # dfs.append(df)\n",
    "        continue\n",
    "    if not fn.startswith(safe_name): \n",
    "        continue\n",
    "    print(fn)\n",
    "    df = pd.read_csv(os.path.join(results_path, fn))\n",
    "    df = df[df['doi/arxiv_id'].isin(base['doi/arxiv_id'])]\n",
    "    metrics = compute_all_metrics(df)\n",
    "    dfs.append(metrics)\n",
    "    # dfs.append(df)\n",
    "    if 'matches' not in df.columns:\n",
    "        continue\n",
    "\n",
    "    df['matches']  = df['matches'].apply(parse_list)\n",
    "    df['file']     = fn\n",
    "    # True if any match in that run for that error\n",
    "    df['detected'] = df['matches'].apply(lambda L: len(L) > 0)\n",
    "    rows.append(df[group_cols + ['file','detected']])\n",
    "\n",
    "detect_df = pd.concat(rows, ignore_index=True)\n",
    "\n",
    "# 2) Pivot to a full detection matrix (fills undetected with False)\n",
    "det = detect_df.pivot_table(\n",
    "    index=group_cols,\n",
    "    columns='file',\n",
    "    values='detected',\n",
    "    fill_value=False\n",
    ")\n",
    "\n",
    "file_list   = det.columns.tolist()\n",
    "total_errors = det.shape[0]\n",
    "\n",
    "# 3) pass@N estimator\n",
    "def pass_at_n(detection_df, n):\n",
    "    chosen = random.sample(file_list, n)\n",
    "    # did any of the N runs catch each error?\n",
    "    return detection_df[chosen].any(axis=1).mean()\n",
    "\n",
    "# 4) Bootstrap 95% CIs\n",
    "np.random.seed(0)\n",
    "n_boot = 1000\n",
    "Ns     = [1,2]\n",
    "boot    = {N: [pass_at_n(det, N) for _ in range(n_boot)] for N in Ns}\n",
    "\n",
    "# 5) Print point estimates + CIs\n",
    "ci = {\n",
    "    N: (\n",
    "        np.percentile(vals, 2.5),   # lower 0.5th percentile\n",
    "        np.percentile(vals, 97.5)   # upper 99.5th percentile\n",
    "    )\n",
    "    for N, vals in boot.items()\n",
    "}\n",
    "\n",
    "# 5) Print point estimates + 99% CIs\n",
    "# 5) Print point estimates + 99% CIs + bootstrap std\n",
    "for N in Ns:\n",
    "    vals = boot[N]\n",
    "    p   = np.mean(vals)\n",
    "    std = np.std(vals, ddof=1)           # bootstrap‐sample standard deviation\n",
    "    lo, hi = ci[N]\n",
    "    print(f\"pass@{N}: {p:.3f} (99% CI: {lo:.3f}–{hi:.3f}), std: {std:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43566f20-2635-47f1-83ef-a745f75926d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "o4_low_resp_df.csv\n",
    "o4_low_1_resp_df.csv\n",
    "o4_low_2_resp_df.csv\n",
    "\n",
    "low\n",
    "pass@1: 0.082 (99% CI: 0.030–0.152), std: 0.052\n",
    "med\n",
    "pass@1: 0.121 (99% CI: 0.121–0.121), std: 0.000\n",
    "high\n",
    "pass@1: 0.163 (99% CI: 0.121–0.212), std: 0.038\n",
    "\n",
    "pass@2: 0.140 (99% CI: 0.091–0.182), std: 0.038\n",
    "pass@3: 0.182 (99% CI: 0.182–0.182), std: 0.000\n",
    "\n",
    "precision_micro    0.114846\n",
    "recall_micro       0.101852\n",
    "PPR                0.050505\n",
    "\n",
    "precision_micro    0.117616\n",
    "recall_micro       0.105165\n",
    "PPR                0.046289\n",
    "\n",
    "o4_med_resp_df.csv\n",
    "o4_med_1_resp_df.csv\n",
    "o4_med_2_resp_df.csv\n",
    "pass@1: 0.121 (99% CI: 0.121–0.121), std: 0.000\n",
    "pass@2: 0.182 (99% CI: 0.182–0.182), std: 0.000\n",
    "pass@3: 0.242 (99% CI: 0.242–0.242), std: 0.000\n",
    "\n",
    "precision_micro    0.080899\n",
    "recall_micro       0.129630\n",
    "PPR                0.101010\n",
    "\n",
    "precision_micro    0.002132\n",
    "recall_micro       0.016038\n",
    "PPR                0.017495\n",
    "\n",
    "o4_high_resp_df.csv\n",
    "o4_high_1_resp_df.csv\n",
    "o4_high_2_resp_df.csv\n",
    "pass@1: 0.150 (99% CI: 0.121–0.212), std: 0.042\n",
    "pass@2: 0.280 (99% CI: 0.212–0.333), std: 0.052\n",
    "pass@3: 0.212 (99% CI: 0.212–0.212), std: 0.000\n",
    "\n",
    "precision_micro    0.092290\n",
    "recall_micro       0.129630\n",
    "PPR                0.070707\n",
    "\n",
    "precision_micro    0.057029\n",
    "recall_micro       0.084863\n",
    "PPR                0.063081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "294d9ddd-65cd-4aef-af69-a6d29052c382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>PPR</th>\n",
       "      <th>per_paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[{'doi/arxiv_id': '10.5539/jsd.v17n6p137', 'k_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>[{'doi/arxiv_id': '10.5539/jsd.v17n6p137', 'k_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>[{'doi/arxiv_id': '10.5539/jsd.v17n6p137', 'k_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    N  precision_micro  recall_micro  precision_macro  recall_macro       PPR  \\\n",
       "0  33         0.035714      0.027778         0.000000      0.015152  0.000000   \n",
       "1  33         0.250000      0.222222         0.000000      0.227273  0.090909   \n",
       "2  33         0.058824      0.055556         0.007576      0.060606  0.060606   \n",
       "\n",
       "                                           per_paper  \n",
       "0  [{'doi/arxiv_id': '10.5539/jsd.v17n6p137', 'k_...  \n",
       "1  [{'doi/arxiv_id': '10.5539/jsd.v17n6p137', 'k_...  \n",
       "2  [{'doi/arxiv_id': '10.5539/jsd.v17n6p137', 'k_...  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low\n",
    "pass@1: 0.121 (99% CI: 0.121–0.121), std: 0.000\n",
    "pass@2: 0.140 (99% CI: 0.091–0.182), std: 0.038\n",
    "\n",
    "med\n",
    "pass@1: 0.121 (99% CI: 0.121–0.121), std: 0.000\n",
    "pass@2: 0.182 (99% CI: 0.182–0.182), std: 0.000\n",
    "\n",
    "high\n",
    "pass@1: 0.150 (99% CI: 0.121–0.212), std: 0.042\n",
    "pass@2: 0.280 (99% CI: 0.212–0.333), std: 0.052"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "4a14e2c3-98ed-4e7a-81a8-55056795bd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision_micro    0.114846\n",
       "recall_micro       0.101852\n",
       "PPR                0.050505\n",
       "dtype: float64"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dfs).dropna(subset=['N'])[['precision_micro','recall_micro','PPR']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "6d55e406-d52f-4679-b452-e2dfd6022ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision_micro    0.117616\n",
       "recall_micro       0.105165\n",
       "PPR                0.046289\n",
       "dtype: float64"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dfs).dropna(subset=['N'])[['precision_micro','recall_micro','PPR']].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a3231b77-e86a-422f-8fb5-17a0d5016801",
   "metadata": {},
   "outputs": [],
   "source": [
    "det = det.reset_index()\n",
    "det['paper_category'] = det['paper_category'].apply(\n",
    "    lambda x: eval(x)[0]\n",
    ")\n",
    "det['error_category'] = det['error_category'].apply(\n",
    "    lambda x: 'Data Inconsistency' if 'data inconsistency' in x.lower() else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "0d459089-5267-4cf0-bad6-eacb31eaff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Assuming det is already loaded with boolean flags for each run in run_cols\n",
    "# Identify run columns (all except metadata and mean_score)\n",
    "meta_cols = ['file', 'doi/arxiv_id', 'error_category', 'error_severity', 'paper_category', 'mean_score']\n",
    "run_cols = [c for c in det.columns if c not in meta_cols]\n",
    "\n",
    "def bootstrap_pass_at_n(df_flags, n, n_boot=1000, seed=0):\n",
    "    random.seed(seed)\n",
    "    vals = []\n",
    "    for _ in range(n_boot):\n",
    "        chosen = random.sample(run_cols, n)\n",
    "        vals.append(df_flags[chosen].any(axis=1).mean())\n",
    "    return np.mean(vals), np.std(vals, ddof=1), np.percentile(vals, 0.5), np.percentile(vals, 99.5)\n",
    "\n",
    "# Compute pass@k by error_category\n",
    "error_stats = []\n",
    "for cat, group in det.groupby('error_category'):\n",
    "    stats = {'category': cat}\n",
    "    for N in [1,2,4]:\n",
    "        mean, std, lo, hi = bootstrap_pass_at_n(group[run_cols], N)\n",
    "        stats.update({\n",
    "            f'pass@{N}_mean': mean,\n",
    "            f'pass@{N}_std': std,\n",
    "        })\n",
    "    error_stats.append(stats)\n",
    "error_df = pd.DataFrame(error_stats)\n",
    "\n",
    "# Compute pass@k by paper_category\n",
    "paper_stats = []\n",
    "for cat, group in det.groupby('paper_category'):\n",
    "    stats = {'category': cat}\n",
    "    for N in [1,2,4]:\n",
    "        mean, std, lo, hi = bootstrap_pass_at_n(group[run_cols], N)\n",
    "        stats.update({\n",
    "            f'pass@{N}_mean': mean,\n",
    "            f'pass@{N}_std': std,\n",
    "        })\n",
    "    paper_stats.append(stats)\n",
    "paper_df = pd.DataFrame(paper_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "28296816-c8f1-4096-95c2-9654c257b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def render_passk_table(error_df: pd.DataFrame, paper_df: pd.DataFrame, model_name: str) -> str:\n",
    "    # Begin LaTeX table\n",
    "    lines = []\n",
    "    lines.append(r\"\\begin{table}[ht]\")\n",
    "    lines.append(r\"  \\centering\")\n",
    "    lines.append(r\"  \\fontsize{8}{9.5}\\selectfont\")\n",
    "    \n",
    "    lines.append(\n",
    "    fr\"  \\caption{{Mean and standard deviation of $\\mathrm{{pass}}@K$ for {model_name} ($K \\in \\{{1,2,4\\}}$) by error category (left) and paper category (right).}}\"\n",
    ")\n",
    "    lines.append(fr\"  \\label{{tab:passk-text-{model_name.lower()}}}\")\n",
    "    lines.append(r\"  \\begin{tabular}{@{} lccc @{\\quad} lccc @{} }\")\n",
    "    lines.append(r\"    \\toprule\")\n",
    "    lines.append(r\"    \\multicolumn{4}{c}{\\textbf{Error Category}} & \\multicolumn{4}{c}{\\textbf{Paper Category}} \\\\\")\n",
    "    lines.append(r\"    \\cmidrule(r){1-4} \\cmidrule(l){5-8}\")\n",
    "    lines.append(r\"   \\multicolumn{4}{c}{\\textbf{Error Category}} & \\multicolumn{4}{c}{\\textbf{Paper Category}} \\\\\")\n",
    "    lines.append(r\"    \\midrule\")\n",
    "    \n",
    "    # Ensure both dfs have same number of rows (pad with blanks if necessary)\n",
    "    max_rows = max(len(error_df), len(paper_df))\n",
    "    for i in range(max_rows):\n",
    "        # Error category row\n",
    "        if i < len(error_df):\n",
    "            e = error_df.iloc[i]\n",
    "            err_row = (\n",
    "                f\"{e['category']} & \"\n",
    "                f\"${e['pass@1_mean']*100:.1f}_{{{e['pass@1_std']*100:.1f}}}$ & \"\n",
    "                f\"${e['pass@2_mean']*100:.1f}_{{{e['pass@2_std']*100:.1f}}}$ & \"\n",
    "                f\"${e['pass@4_mean']*100:.1f}_{{{e['pass@4_std']*100:.1f}}}$\"\n",
    "            )\n",
    "        else:\n",
    "            err_row = \"& & &\"\n",
    "        # Paper category row\n",
    "        if i < len(paper_df):\n",
    "            p = paper_df.iloc[i]\n",
    "            pap_row = (\n",
    "                f\"{p['category']} & \"\n",
    "                f\"${p['pass@1_mean']*100:.1f}_{{{p['pass@1_std']*100:.1f}}}$ & \"\n",
    "                f\"${p['pass@2_mean']*100:.1f}_{{{p['pass@2_std']*100:.1f}}}$ & \"\n",
    "                f\"${p['pass@4_mean']*100:.1f}_{{{p['pass@4_std']*100:.1f}}}$\"\n",
    "            )\n",
    "        else:\n",
    "            pap_row = \"& & &\"\n",
    "        lines.append(f\"    {err_row} & {pap_row} \\\\\\\\\")\n",
    "    \n",
    "    lines.append(r\"    \\bottomrule\")\n",
    "    lines.append(r\"  \\end{tabular}\")\n",
    "    lines.append(r\"\\end{table}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Example usage:\n",
    "# latex_code = render_passk_table(error_df, paper_df, \"o3\")\n",
    "# print(latex_code)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "45e4f49e-aff8-47f9-aebc-ca8557e58ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "  \\centering\n",
      "  \\fontsize{8}{9.5}\\selectfont\n",
      "  \\caption{Mean and standard deviation of $\\mathrm{pass}@K$ for openrouter_meta-llama_llama-4-s ($K \\in \\{1,2,4\\}$) by error category (left) and paper category (right).}\n",
      "  \\label{tab:passk-text-openrouter_meta-llama_llama-4-s}\n",
      "  \\begin{tabular}{@{} lccc @{\\quad} lccc @{} }\n",
      "    \\toprule\n",
      "    \\multicolumn{4}{c}{\\textbf{Error Category}} & \\multicolumn{4}{c}{\\textbf{Paper Category}} \\\\\n",
      "    \\cmidrule(r){1-4} \\cmidrule(l){5-8}\n",
      "   \\multicolumn{4}{c}{\\textbf{Error Category}} & \\multicolumn{4}{c}{\\textbf{Paper Category}} \\\\\n",
      "    \\midrule\n",
      "    Data Inconsistency & $6.9_{8.2}$ & $13.1_{9.7}$ & $23.9_{9.2}$ & Biology & $6.5_{16.8}$ & $13.1_{22.0}$ & $29.6_{24.6}$ \\\\\n",
      "    Equation / proof & $0.8_{1.3}$ & $1.5_{1.5}$ & $2.6_{1.0}$ & Computer Science & $2.3_{3.7}$ & $4.1_{4.2}$ & $7.2_{2.8}$ \\\\\n",
      "    Experiment setup & $0.0_{0.0}$ & $0.0_{0.0}$ & $0.0_{0.0}$ & Environmental Science & $14.1_{22.5}$ & $26.2_{25.0}$ & $42.2_{18.2}$ \\\\\n",
      "    Reagent identity & $4.3_{11.2}$ & $8.7_{14.6}$ & $19.7_{16.4}$ & Materials Science & $6.5_{16.8}$ & $13.1_{22.0}$ & $29.6_{24.6}$ \\\\\n",
      "    Statistical reporting & $0.0_{0.0}$ & $0.0_{0.0}$ & $0.0_{0.0}$ & Mathematics & $0.0_{0.0}$ & $0.0_{0.0}$ & $0.0_{0.0}$ \\\\\n",
      "    & & & & Medicine & $0.0_{0.0}$ & $0.0_{0.0}$ & $0.0_{0.0}$ \\\\\n",
      "    & & & & Multidisciplinary & $0.0_{0.0}$ & $0.0_{0.0}$ & $0.0_{0.0}$ \\\\\n",
      "    & & & & Physics & $0.0_{0.0}$ & $0.0_{0.0}$ & $0.0_{0.0}$ \\\\\n",
      "    \\bottomrule\n",
      "  \\end{tabular}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "latex_code = render_passk_table(error_df, paper_df,model_name)\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b3f2e-1514-4142-882e-aadc1fa8d65a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde0d21-fd3c-4f4f-80b9-0d9b5383212d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
